name: Run Crawler

on:
  workflow_dispatch:
    inputs:
      source:
        description: 'Crawler source to run'
        required: true
        type: choice
        options:
          # ê´‘ì—­ì‹œ/ë„ (14ê°œ)
          - seoul
          - busan
          - daegu
          - incheon
          - gwangju
          - daejeon
          - ulsan
          - sejong
          - gyeonggi
          - gangwon
          - chungbuk
          - chungnam
          - jeonbuk
          - jeonnam
          - gyeongbuk
          - gyeongnam
          - jeju
          # ê²½ê¸°ë„ ì‹œ/êµ° (18ê°œ)
          - seongnam
          - goyang
          - uijeongbu
          - namyangju
          - bucheon
          - gimpo
          - gwangmyeong
          - gwangjuhanam
          - gurinamyangju
          - anseong
          - pyeongtaek
          - paju
          - yangpyeong
          - pocheon
          - yeoncheon
          - dongducheonyangjyu
          - gapyeong1
          - gapyeong2
      mode:
        description: 'Crawl mode (run or test)'
        required: false
        default: 'run'
        type: choice
        options:
          - run
          - test
  schedule:
    - cron: '0 1 * * *'  # UTC 1 AM = Korea 10 AM
    - cron: '0 9 * * *'  # UTC 9 AM = Korea 6 PM

jobs:
  crawl-manual:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: crawler/package-lock.json

      - name: Install dependencies
        working-directory: crawler
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('crawler/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        working-directory: crawler
        run: |
          # Microsoft íŒ¨í‚¤ì§€ ì €ì¥ì†Œ ë¬¸ì œ ìš°íšŒ: deps ì—†ì´ ì„¤ì¹˜ í›„ í•„ìš”í•œ depsë§Œ ìˆ˜ë™ ì„¤ì¹˜
          npx playwright install chromium
          # í•„ìˆ˜ ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜ (Microsoft ì €ì¥ì†Œ ë¶ˆí•„ìš”)
          sudo apt-get update
          sudo apt-get install -y libnss3 libnspr4 libatk1.0-0 libatk-bridge2.0-0 libcups2 libdrm2 libxkbcommon0 libxcomposite1 libxdamage1 libxfixes3 libxrandr2 libgbm1 libasound2 libpango-1.0-0 libcairo2

      - name: Run crawler
        working-directory: crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CRAWL_MODE: ${{ github.event.inputs.mode }}
          CRAWLER_SOURCE: ${{ github.event.inputs.source }}
        run: |
          echo "ğŸš€ Starting crawler: $CRAWLER_SOURCE"
          echo "ğŸ”§ Mode: $CRAWL_MODE"
          node index.js --source=$CRAWLER_SOURCE

  crawl-scheduled:
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        source:
          # ê´‘ì—­ì‹œ/ë„ (14ê°œ)
          - seoul
          - busan
          - daegu
          - incheon
          - gwangju
          - daejeon
          - ulsan
          - sejong
          - gyeonggi
          - gangwon
          - chungbuk
          - chungnam
          - jeonbuk
          - jeonnam
          - gyeongbuk
          - gyeongnam
          - jeju
          # ê²½ê¸°ë„ ì‹œ/êµ° (18ê°œ)
          - seongnam
          - goyang
          - uijeongbu
          - namyangju
          - bucheon
          - gimpo
          - gwangmyeong
          - gwangjuhanam
          - gurinamyangju
          - anseong
          - pyeongtaek
          - paju
          - yangpyeong
          - pocheon
          - yeoncheon
          - dongducheonyangjyu
          - gapyeong1
          - gapyeong2

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: crawler/package-lock.json

      - name: Install dependencies
        working-directory: crawler
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('crawler/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        working-directory: crawler
        run: |
          # Microsoft íŒ¨í‚¤ì§€ ì €ì¥ì†Œ ë¬¸ì œ ìš°íšŒ: deps ì—†ì´ ì„¤ì¹˜ í›„ í•„ìš”í•œ depsë§Œ ìˆ˜ë™ ì„¤ì¹˜
          npx playwright install chromium
          # í•„ìˆ˜ ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜ (Microsoft ì €ì¥ì†Œ ë¶ˆí•„ìš”)
          sudo apt-get update
          sudo apt-get install -y libnss3 libnspr4 libatk1.0-0 libatk-bridge2.0-0 libcups2 libdrm2 libxkbcommon0 libxcomposite1 libxdamage1 libxfixes3 libxrandr2 libgbm1 libasound2 libpango-1.0-0 libcairo2

      - name: Run crawler
        shell: bash
        working-directory: crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CRAWL_MODE: 'run'
        run: |
          echo "ğŸš€ Starting crawler: ${{ matrix.source }}"
          node index.js --source=${{ matrix.source }}
