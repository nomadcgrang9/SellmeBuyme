name: Run Crawler

on:
  workflow_dispatch:
    inputs:
      crawler_source:
        description: 'Crawler source to run'
        required: true
        type: choice
        options:
          - gyeonggi
          - seongnam
          - uijeongbu
          - namyangju
          - gwangju
          - jeonbuk
          - jeonnam
          - jeju
          - incheon
          - seoul
          - gangwon
          - sejong
      mode:
        description: 'Crawl mode (run or test)'
        required: false
        default: 'run'
        type: choice
        options:
          - run
          - test
  schedule:
    # Îß§Ïùº KST 07:00 (UTC 22:00)
    - cron: '0 22 * * *'

jobs:
  crawl-manual:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: crawler/package-lock.json

      - name: Install dependencies
        working-directory: crawler
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('crawler/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        working-directory: crawler
        run: npx playwright install chromium --with-deps

      - name: Run crawler
        working-directory: crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          CRAWLER_SOURCE: ${{ github.event.inputs.crawler_source }}
          CRAWL_MODE: ${{ github.event.inputs.mode }}
        run: |
          echo "üöÄ Starting crawler: $CRAWLER_SOURCE"
          echo "üîß Mode: $CRAWL_MODE"
          node index.js --source=$CRAWLER_SOURCE

  crawl-scheduled:
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        source:
          - gyeonggi
          - seongnam
          - uijeongbu
          - namyangju
          - gwangju
          - jeonbuk
          - jeonnam
          - jeju
          - incheon
          - seoul
          - gangwon
          - sejong

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: crawler/package-lock.json

      - name: Install dependencies
        working-directory: crawler
        run: npm ci

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('crawler/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-

      - name: Install Playwright browsers
        working-directory: crawler
        run: npx playwright install chromium --with-deps

      - name: Run crawler
        working-directory: crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "üöÄ Starting crawler: ${{ matrix.source }}"
          node index.js --source=${{ matrix.source }}
