import { createClient } from '@supabase/supabase-js';
import { readFileSync } from 'fs';
import * as dotenv from 'dotenv';

dotenv.config();

const supabase = createClient(
  process.env.VITE_SUPABASE_URL!,
  process.env.VITE_SUPABASE_ANON_KEY!
);

async function forceUpload() {
  const boardId = 'f72665d5-eaa1-4f2f-af98-97e27bd441cf';
  const filePath = 'crawler/sources/ë‚¨ì–‘ì£¼êµìœ¡ì§€ì›ì²­-êµ¬ì¸êµ¬ì§-í…ŒìŠ¤íŠ¸.js';

  console.log('ğŸ“ ê°•ì œ ì—…ë¡œë“œ ì‹œì‘...\n');

  const code = readFileSync(filePath, 'utf-8');
  console.log(`âœ… íŒŒì¼ ì½ê¸° ì™„ë£Œ: ${code.length}ì\n`);

  const { error } = await supabase
    .from('crawl_boards')
    .update({ crawler_source_code: code })
    .eq('id', boardId);

  if (error) {
    console.error('âŒ ì—…ë¡œë“œ ì‹¤íŒ¨:', error);
    process.exit(1);
  }

  console.log('âœ… ì—…ë¡œë“œ ì™„ë£Œ!\n');

  // ê²€ì¦
  const { data } = await supabase
    .from('crawl_boards')
    .select('crawler_source_code')
    .eq('id', boardId)
    .single();

  console.log(`ğŸ¯ ê²€ì¦: DBì— ì €ì¥ëœ ì½”ë“œ ê¸¸ì´ = ${data?.crawler_source_code?.length}ì`);
}

forceUpload();
