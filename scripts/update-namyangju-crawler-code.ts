import { createClient } from '@supabase/supabase-js';
import { readFileSync } from 'fs';
import { join } from 'path';
import * as dotenv from 'dotenv';

dotenv.config();

// SERVICE_ROLE_KEY ì‚¬ìš©í•˜ì—¬ RLS ìš°íšŒ
const supabase = createClient(
  process.env.VITE_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

async function updateCrawlerCode() {
  console.log('=== ë‚¨ì–‘ì£¼ í¬ë¡¤ëŸ¬ ì½”ë“œ ì—…ë°ì´íŠ¸ ===\n');

  // 1. ë¡œì»¬ íŒŒì¼ì—ì„œ ì½”ë“œ ì½ê¸°
  const localFilePath = join(process.cwd(), 'crawler', 'sources', 'ë‚¨ì–‘ì£¼êµìœ¡ì§€ì›ì²­-êµ¬ì¸êµ¬ì§.js');
  const crawlerCode = readFileSync(localFilePath, 'utf-8');

  console.log(`âœ… ë¡œì»¬ íŒŒì¼ ì½ê¸° ì™„ë£Œ`);
  console.log(`   ê²½ë¡œ: ${localFilePath}`);
  console.log(`   ì½”ë“œ ê¸¸ì´: ${crawlerCode.length}ì\n`);

  // 2. ë‚¨ì–‘ì£¼ board ID (GitHub Actions ë¡œê·¸ì—ì„œ í™•ì¸)
  const boardId = 'f72665d5-eaa1-4f2f-af98-97e27bd441cf';

  // crawl_boardsì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
  const { data: board, error: boardError } = await supabase
    .from('crawl_boards')
    .select('id, name, crawler_source_code')
    .eq('id', boardId)
    .single();

  if (boardError || !board) {
    console.error('âŒ ë‚¨ì–‘ì£¼ ê²Œì‹œíŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:', boardError?.message);
    return;
  }
  console.log(`ğŸ“Œ ì—…ë°ì´íŠ¸ ëŒ€ìƒ:`);
  console.log(`   ID: ${board.id}`);
  console.log(`   ì´ë¦„: ${board.name}`);
  console.log(`   ê¸°ì¡´ ì½”ë“œ ê¸¸ì´: ${board.crawler_source_code?.length || 0}ì\n`);

  // 3. DB ì—…ë°ì´íŠ¸
  const { error: updateError } = await supabase
    .from('crawl_boards')
    .update({ crawler_source_code: crawlerCode })
    .eq('id', board.id);

  if (updateError) {
    console.error('âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', updateError.message);
    return;
  }

  console.log(`âœ… í¬ë¡¤ëŸ¬ ì½”ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!`);
  console.log(`   ìƒˆ ì½”ë“œ ê¸¸ì´: ${crawlerCode.length}ì\n`);

  // 4. ê²€ì¦
  const { data: updated } = await supabase
    .from('crawl_boards')
    .select('crawler_source_code')
    .eq('id', board.id)
    .single();

  console.log(`ğŸ¯ ê²€ì¦ ê²°ê³¼:`);
  console.log(`   DBì— ì €ì¥ëœ ì½”ë“œ ê¸¸ì´: ${updated?.crawler_source_code?.length || 0}ì`);
  console.log(`   ì¼ì¹˜ ì—¬ë¶€: ${updated?.crawler_source_code?.length === crawlerCode.length ? 'âœ… ì„±ê³µ' : 'âŒ ì‹¤íŒ¨'}\n`);

  console.log('âœ… ì‘ì—… ì™„ë£Œ! ì´ì œ GitHub Actionsì—ì„œ í¬ë¡¤ëŸ¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
}

updateCrawlerCode();
