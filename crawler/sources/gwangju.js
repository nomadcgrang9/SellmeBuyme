import { getExistingJobBySource } from '../lib/supabase.js';

/**
 * ê´‘ì£¼ê´‘ì—­ì‹œêµìœ¡ì²­ í¬ë¡¤ëŸ¬
 *
 * ê·œì¹™: ê²Œì‹œíŒ 1í˜ì´ì§€(ìµœì‹  í˜ì´ì§€)ë§Œ í¬ë¡¤ë§
 * - ì¤‘ë³µëœ ê²ƒë§Œ ì œì™¸ (source_url ê¸°ì¤€)
 */
export async function crawlGwangju(page, config) {
    console.log(`\nğŸ“ ${config.name} í¬ë¡¤ë§ ì‹œì‘`);

    // í—¤ë” ì„¤ì • (ë´‡ íƒì§€ ë°©ì§€)
    await page.setExtraHTTPHeaders({
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
    });

    let jobs = [];
    let skippedCount = 0;

    try {
        // Phase 1: ëª©ë¡ 1í˜ì´ì§€ ìˆ˜ì§‘
        const collectedItems = [];

        console.log(`ğŸ“„ ëª©ë¡ í˜ì´ì§€ 1 í¬ë¡¤ë§...`);
        const listUrl = `${config.baseUrl}&page=1`;
        await page.goto(listUrl, { waitUntil: 'domcontentloaded', timeout: 60000 });

        const rows = await page.$$('table tbody tr');

        for (const row of rows) {
            const columns = await row.$$('td');
            if (columns.length < 5) continue;

            const numText = await columns[0].textContent().then(t => t.trim());
            const titleText = await columns[2].innerText().then(t => t.trim());
            const dateText = await columns[4].textContent().then(t => t.trim());
            const linkEl = await columns[2].$('a');

            if (!titleText || !linkEl) continue;
            const linkHref = await linkEl.getAttribute('href');

            // ë§í¬ ì ˆëŒ€ê²½ë¡œ ë³€í™˜
            let fullLink = linkHref;
            if (linkHref && !linkHref.startsWith('http')) {
                fullLink = new URL(linkHref, config.baseUrl).href;
            }

            collectedItems.push({
                title: titleText,
                date: dateText.replace(/\./g, '-'),
                link: fullLink,
                schoolName: "ê´‘ì£¼ê´‘ì—­ì‹œêµìœ¡ì²­",
            });
        }

        console.log(`âœ… Phase 1 ì™„ë£Œ: ${collectedItems.length}ê°œ ë§í¬ ì‹ë³„ (1í˜ì´ì§€)`);

        // SAFETY ì„¤ì • (150/15/0.8/10 í†µì¼)
        const SAFETY = {
            maxItems: 150,                // ì ˆëŒ€ ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜
            consecutiveDuplicateLimit: 10, // ì—°ì† ì¤‘ë³µ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
        };

        let processedCount = 0;
        let consecutiveDuplicates = 0;

        // Phase 2: ìƒì„¸ ìˆ˜ì§‘ (ì¤‘ë³µë§Œ ì œì™¸)
        for (const item of collectedItems) {
            // ì•ˆì „ì¥ì¹˜: ìµœëŒ€ ê°œìˆ˜
            if (processedCount >= SAFETY.maxItems) {
                console.log(`  âš ï¸ ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜(${SAFETY.maxItems}) ë„ë‹¬`);
                break;
            }
            // ì¤‘ë³µ ì²´í¬ (source_url ê¸°ì¤€)
            const existing = await getExistingJobBySource(item.link);
            if (existing) {
                skippedCount++;
                consecutiveDuplicates++;
                // ì—°ì† ì¤‘ë³µ í•œê³„ ë„ë‹¬ ì‹œ ì¤‘ë‹¨
                if (consecutiveDuplicates >= SAFETY.consecutiveDuplicateLimit) {
                    console.log(`  âš ï¸ ì—°ì† ì¤‘ë³µ ${SAFETY.consecutiveDuplicateLimit}ê°œ ë„ë‹¬ - í¬ë¡¤ë§ ì¢…ë£Œ`);
                    break;
                }
                continue;
            }

            // ì‹ ê·œ í•­ëª© ë°œê²¬ ì‹œ ì—°ì† ì¤‘ë³µ ì¹´ìš´í„° ë¦¬ì…‹
            consecutiveDuplicates = 0;
            processedCount++;

            console.log(`  ğŸ” ìƒì„¸ í¬ë¡¤ë§: ${item.title}`);
            try {
                const detailData = await crawlDetailPage(page, item.link);
                jobs.push({
                    ...item,
                    ...detailData,
                    location: config.region
                });
                await page.waitForTimeout(500);
            } catch (e) {
                console.error(`  âš ï¸ ìƒì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨ (${item.title}): ${e.message}`);
            }
        }

    } catch (error) {
        console.error(`âŒ í¬ë¡¤ë§ ì¹˜ëª…ì  ì˜¤ë¥˜: ${error.message}`);
        throw error;
    }

    console.log(`\nâœ… ${config.name} í¬ë¡¤ë§ ì™„ë£Œ`);
    console.log(`   - ì‹ ê·œ: ${jobs.length}ê°œ`);
    console.log(`   - ì¤‘ë³µ ìŠ¤í‚µ: ${skippedCount}ê°œ\n`);

    return jobs;
}

async function crawlDetailPage(page, url) {
    await page.goto(url, { waitUntil: 'networkidle', timeout: 45000 });

    // ìƒì„¸ ì •ë³´ ì¶”ì¶œ (ë§ˆê°ì¼ í¬í•¨)
    const detailInfo = await page.evaluate(() => {
        const result = {
            deadline: null,
            organization: null,
        };

        // dt/dd ë˜ëŠ” th/td íŒ¨í„´ì—ì„œ ë§ˆê°ì¼ ì¶”ì¶œ
        const terms = document.querySelectorAll('dt, th, .info_tit');
        terms.forEach(term => {
            const label = term.textContent?.trim() || '';
            const next = term.nextElementSibling;
            const value = next?.textContent?.trim() || '';

            if (label.includes('ë§ˆê°') || label.includes('ì ‘ìˆ˜ê¸°ê°„') || label.includes('ëª¨ì§‘ê¸°ê°„')) {
                result.deadline = value;
            }
            if (label.includes('ê¸°ê´€') || label.includes('í•™êµ') || label.includes('ì‘ì„±ì')) {
                result.organization = value;
            }
        });

        // í…Œì´ë¸” í˜•íƒœì—ì„œë„ ì‹œë„
        const rows = document.querySelectorAll('table tr');
        rows.forEach(row => {
            const th = row.querySelector('th');
            const td = row.querySelector('td');
            if (!th || !td) return;

            const label = th.textContent?.trim() || '';
            const value = td.textContent?.trim() || '';

            if (label.includes('ë§ˆê°') || label.includes('ì ‘ìˆ˜ê¸°ê°„') || label.includes('ëª¨ì§‘ê¸°ê°„')) {
                result.deadline = value;
            }
        });

        return result;
    });

    const content = await page.evaluate(() => {
        const el = document.querySelector('.view_con') || document.querySelector('#xb_view') || document.querySelector('#board_view') || document.querySelector('.board_view');
        return el ? el.innerText.trim() : '';
    });

    const attachments = await page.evaluate(() => {
        const links = Array.from(document.querySelectorAll('.file_down a, a[href*="download"]'));
        return links.map(a => ({
            name: a.innerText.trim(),
            url: a.href
        })).filter(f => f.url && f.name);
    });

    return {
        detailContent: content,
        attachments: attachments,
        attachmentUrl: attachments.length > 0 ? attachments[0].url : null,
        attachmentFilename: attachments.length > 0 ? attachments[0].name : null,
        deadline: detailInfo.deadline,
        organization: detailInfo.organization,
    };
}

