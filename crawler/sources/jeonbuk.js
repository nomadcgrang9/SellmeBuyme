import { getExistingJobBySource } from '../lib/supabase.js';

/**
 * ì „ë¶íŠ¹ë³„ìì¹˜ë„êµìœ¡ì²­ í¬ë¡¤ëŸ¬
 *
 * ê·œì¹™: ê²Œì‹œíŒ 1í˜ì´ì§€(ìµœì‹  í˜ì´ì§€)ë§Œ í¬ë¡¤ë§
 * - ì¤‘ë³µëœ ê²ƒë§Œ ì œì™¸ (source_url ê¸°ì¤€)
 */
export async function crawlJeonbuk(page, config) {
    console.log(`\nğŸ“ ${config.name} í¬ë¡¤ë§ ì‹œì‘`);
    let jobs = [];
    let skippedCount = 0;

    try {
        // Phase 1: ëª©ë¡ 1í˜ì´ì§€ì—ì„œ ë§í¬ ìˆ˜ì§‘
        const collectedItems = [];

        console.log(`ğŸ“„ ëª©ë¡ í˜ì´ì§€ 1 í¬ë¡¤ë§...`);
        const listUrl = `${config.baseUrl}&startPage=1`;
        await page.goto(listUrl, { waitUntil: 'domcontentloaded' });

        const rows = await page.$$('table.bbs_list_t tbody tr');

        for (const row of rows) {
            const columns = await row.$$('td');
            if (columns.length < 5) continue;

            const numText = await columns[0].innerText().then(t => t.trim());
            const schoolText = await columns[2].innerText().then(t => t.trim());
            const titleText = await columns[3].innerText().then(t => t.trim());
            const linkEl = await columns[2].$('a');

            if (!linkEl) continue;
            const href = await linkEl.getAttribute('href');
            const fullLink = new URL(href, config.baseUrl).href;

            collectedItems.push({
                numText,
                title: titleText,
                schoolName: schoolText,
                link: fullLink,
                location: config.region,
            });
        }

        console.log(`âœ… Phase 1: ${collectedItems.length}ê°œ ë§í¬ ìˆ˜ì§‘ (1í˜ì´ì§€)`);

        // Phase 2: ìƒì„¸ í˜ì´ì§€ ìˆ˜ì§‘ (ì¤‘ë³µë§Œ ì œì™¸)
        for (const item of collectedItems) {
            // ì¤‘ë³µ ì²´í¬ (source_url ê¸°ì¤€)
            const existing = await getExistingJobBySource(item.link);
            if (existing) {
                skippedCount++;
                continue;
            }

            console.log(`  ğŸ” ìƒì„¸ í™•ì¸: ${item.title}`);
            try {
                const detailData = await crawlDetailPage(page, item.link);

                jobs.push({
                    ...item,
                    date: detailData.postDate || new Date().toISOString().split('T')[0],
                    ...detailData
                });

                await page.waitForTimeout(300);
            } catch (e) {
                console.warn(`  âš ï¸ ìƒì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨ (${item.title}): ${e.message}`);
            }
        }

    } catch (e) {
        console.error(e);
        throw e;
    }

    console.log(`\nâœ… ${config.name} í¬ë¡¤ë§ ì™„ë£Œ`);
    console.log(`   - ì‹ ê·œ: ${jobs.length}ê°œ`);
    console.log(`   - ì¤‘ë³µ ìŠ¤í‚µ: ${skippedCount}ê°œ\n`);

    return jobs;
}

async function crawlDetailPage(page, url) {
    try {
        await page.goto(url, { waitUntil: 'domcontentloaded' });

        const postDate = await page.evaluate(() => {
            // ë¨¼ì € ê¸°ì¡´ ë°©ì‹ ì‹œë„
            const dds = Array.from(document.querySelectorAll('.board_view_info dd'));
            for (const dd of dds) {
                if (dd.innerText.includes('ì‘ì„±ì¼')) {
                    const match = dd.innerText.match(/\d{4}-\d{2}-\d{2}/);
                    if (match) return match[0];
                }
            }
            // .bbs_view ë³¸ë¬¸ì—ì„œ ì‘ì„±ì¼ íŒ¨í„´ ì°¾ê¸°
            const view = document.querySelector('.bbs_view');
            if (view) {
                const text = view.innerText;
                const regDateMatch = text.match(/ì‘ì„±ì¼\s*:?\s*(\d{4}-\d{2}-\d{2})/);
                if (regDateMatch) return regDateMatch[1];
            }
            return null;
        });

        const content = await page.evaluate(() => {
            const el = document.querySelector('.bbs_view') || document.querySelector('.board_view_con');
            return el ? el.innerText.trim() : '';
        });

        const attachments = await page.evaluate(() => {
            return Array.from(document.querySelectorAll('.file_down a, .view_file a, a[href*="download"]')).map(a => ({
                name: a.innerText.trim(),
                url: a.href
            })).filter(a => a.name && a.url);
        });

        return {
            postDate,
            detailContent: content,
            attachments,
            attachmentUrl: attachments[0]?.url,
            attachmentFilename: attachments[0]?.name || null
        };
    } catch { return {}; }
}

