/**
 * Supabase Edge Function: AI í¬ë¡¤ëŸ¬ ìë™ ìƒì„±
 * 
 * Phase 5 íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ:
 * - Phase 5-1: ê²Œì‹œíŒ êµ¬ì¡° ë¶„ì„ (boardAnalyzer)
 * - Phase 5-2: í¬ë¡¤ëŸ¬ ì½”ë“œ ìƒì„± (codeGenerator)
 * - Phase 5-3: Sandbox í…ŒìŠ¤íŠ¸ (sandbox)
 * - Phase 5-4: Self-Correction Loop (selfCorrection)
 * 
 * ìš”ì²­:
 * POST /functions/v1/generate-crawler
 * {
 *   "submissionId": "uuid",
 *   "boardName": "êµ¬ë¦¬ë‚¨ì–‘ì£¼êµìœ¡ì§€ì›ì²­",
 *   "boardUrl": "https://www.goegn.kr/...",
 *   "adminUserId": "uuid"
 * }
 * 
 * ì‘ë‹µ:
 * {
 *   "success": true,
 *   "crawlerId": "namyangju",
 *   "crawlerCode": "...",
 *   "crawlBoardId": "uuid",
 *   "message": "í¬ë¡¤ëŸ¬ ìƒì„± ì™„ë£Œ"
 * }
 */

// Supabase Edge Function - Deno ëŸ°íƒ€ì„ì—ì„œ ìë™ìœ¼ë¡œ ì œê³µë¨

interface GenerateCrawlerRequest {
  submissionId: string
  boardName: string
  boardUrl: string
  adminUserId: string
}

interface GenerateCrawlerResponse {
  success: boolean
  crawlerId?: string
  crawlerCode?: string
  crawlBoardId?: string
  message: string
  error?: string
}

serve(async (req: Request) => {
  // CORS ì²˜ë¦¬
  if (req.method === 'OPTIONS') {
    return new Response('ok', {
      headers: {
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type, Authorization',
      },
    })
  }

  if (req.method !== 'POST') {
    return new Response(
      JSON.stringify({ success: false, message: 'POST ìš”ì²­ë§Œ í—ˆìš©ë©ë‹ˆë‹¤' }),
      { status: 405, headers: { 'Content-Type': 'application/json' } }
    )
  }

  try {
    const payload: GenerateCrawlerRequest = await req.json()
    
    // í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if (!payload.submissionId || !payload.boardName || !payload.boardUrl || !payload.adminUserId) {
      return new Response(
        JSON.stringify({
          success: false,
          message: 'í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: submissionId, boardName, boardUrl, adminUserId',
        }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      )
    }

    console.log('[generate-crawler] ìš”ì²­ ìˆ˜ì‹ :', {
      submissionId: payload.submissionId,
      boardName: payload.boardName,
      boardUrl: payload.boardUrl,
    })

    // Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    const supabaseUrl = Deno.env.get('SUPABASE_URL')
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')

    if (!supabaseUrl || !supabaseServiceKey) {
      throw new Error('Supabase í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì •')
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey)

    // Phase 5 íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ
    console.log('[generate-crawler] Phase 5 íŒŒì´í”„ë¼ì¸ ì‹œì‘...')

    // í¬ë¡¤ëŸ¬ ID ìƒì„±
    const crawlerId = payload.boardName
      .toLowerCase()
      .replace(/\s+/g, '_')
      .replace(/[^a-z0-9_]/g, '')

    // âœ… ìƒ˜í”Œ í¬ë¡¤ëŸ¬ ìƒì„± (ì‹¤ì œë¡œëŠ” AI ë¶„ì„ í•„ìš”)
    const crawlerCode = generateSampleCrawler(payload.boardName, payload.boardUrl)
    
    console.log('[generate-crawler] âš ï¸ ì£¼ì˜: í˜„ì¬ëŠ” ìƒ˜í”Œ í¬ë¡¤ëŸ¬ë§Œ ìƒì„±ë©ë‹ˆë‹¤.')
    console.log('[generate-crawler] ì‹¤ì œ AI ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:')
    console.log('[generate-crawler]   1. boardAnalyzer - ê²Œì‹œíŒ êµ¬ì¡° ë¶„ì„')
    console.log('[generate-crawler]   2. codeGenerator - AI ê¸°ë°˜ í¬ë¡¤ëŸ¬ ì½”ë“œ ìƒì„±')
    console.log('[generate-crawler]   3. sandbox - ìƒì„±ëœ ì½”ë“œ í…ŒìŠ¤íŠ¸')
    console.log('[generate-crawler]   4. selfCorrection - ì˜¤ë¥˜ ìˆ˜ì • ë£¨í”„')

    // crawl_boards í…Œì´ë¸”ì— ë“±ë¡
    const { data: crawlBoard, error: crawlBoardError } = await supabase
      .from('crawl_boards')
      .insert({
        name: payload.boardName,
        board_url: payload.boardUrl,
        category: 'job',
        description: `AI ìë™ ìƒì„± í¬ë¡¤ëŸ¬ - ${payload.boardName}`,
        is_active: true,  // âœ… ì¦‰ì‹œ í™œì„±í™”í•˜ì—¬ í¬ë¡¤ë§ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
        status: 'active',
        crawl_batch_size: 10,
        crawler_source_code: crawlerCode,  // âœ… ìƒì„±ëœ í¬ë¡¤ëŸ¬ ì½”ë“œ ì €ì¥
        created_by: payload.adminUserId,
        approved_by: payload.adminUserId,
        approved_at: new Date().toISOString(),
      })
      .select('id')
      .single()

    if (crawlBoardError) {
      throw new Error(`crawl_boards ë“±ë¡ ì‹¤íŒ¨: ${crawlBoardError.message}`)
    }

    // dev_board_submissions í…Œì´ë¸” ì—…ë°ì´íŠ¸
    const { error: updateError } = await supabase
      .from('dev_board_submissions')
      .update({
        status: 'approved',
        crawl_board_id: crawlBoard.id,
        approved_by: payload.adminUserId,
        approved_at: new Date().toISOString(),
      })
      .eq('id', payload.submissionId)

    if (updateError) {
      console.warn('[generate-crawler] dev_board_submissions ì—…ë°ì´íŠ¸ ê²½ê³ :', updateError)
    }

    console.log('[generate-crawler] í¬ë¡¤ëŸ¬ ìƒì„± ì™„ë£Œ:', {
      crawlerId,
      crawlBoardId: crawlBoard.id,
    })

    // âœ… GitHub Actions ì›Œí¬í”Œë¡œìš° ìë™ íŠ¸ë¦¬ê±° (ì¦‰ì‹œ í¬ë¡¤ë§ ì‹¤í–‰)
    const githubToken = Deno.env.get('GITHUB_TOKEN')
    if (githubToken) {
      console.log('[generate-crawler] GitHub Actions íŠ¸ë¦¬ê±° ì‹œì‘...')
      
      try {
        const githubResponse = await fetch(
          'https://api.github.com/repos/nomadcgrang9/SellmeBuyme/actions/workflows/run-crawler.yml/dispatches',
          {
            method: 'POST',
            headers: {
              'Authorization': `token ${githubToken}`,
              'Accept': 'application/vnd.github.v3+json',
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              ref: 'main',
              inputs: {
                board_id: crawlBoard.id,
                crawl_mode: 'run',
              },
            }),
          }
        )

        if (githubResponse.ok) {
          console.log('[generate-crawler] GitHub Actions íŠ¸ë¦¬ê±° ì„±ê³µ')
        } else {
          const errorText = await githubResponse.text()
          console.warn('[generate-crawler] GitHub Actions íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', errorText)
        }
      } catch (githubError) {
        console.warn('[generate-crawler] GitHub Actions íŠ¸ë¦¬ê±° ì˜¤ë¥˜:', githubError)
        // íŠ¸ë¦¬ê±° ì‹¤íŒ¨í•´ë„ í¬ë¡¤ëŸ¬ëŠ” ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰
      }
    } else {
      console.warn('[generate-crawler] GITHUB_TOKEN í™˜ê²½ë³€ìˆ˜ ì—†ìŒ - ìë™ í¬ë¡¤ë§ ìŠ¤í‚µ')
    }

    const response: GenerateCrawlerResponse = {
      success: true,
      crawlerId,
      crawlerCode,
      crawlBoardId: crawlBoard.id,
      message: `í¬ë¡¤ëŸ¬ ìƒì„± ì™„ë£Œ: ${payload.boardName}`,
    }

    return new Response(JSON.stringify(response), {
      status: 200,
      headers: {
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*',
      },
    })
  } catch (error) {
    console.error('[generate-crawler] ì˜¤ë¥˜:', error)

    const response: GenerateCrawlerResponse = {
      success: false,
      message: 'í¬ë¡¤ëŸ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ',
      error: error instanceof Error ? error.message : String(error),
    }

    return new Response(JSON.stringify(response), {
      status: 500,
      headers: {
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*',
      },
    })
  }
})

/**
 * ìƒ˜í”Œ í¬ë¡¤ëŸ¬ ì½”ë“œ ìƒì„± (ì„ì‹œ)
 * ì‹¤ì œë¡œëŠ” Phase 5 íŒŒì´í”„ë¼ì¸ì—ì„œ ìƒì„±ëœ ì½”ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
 */
function generateSampleCrawler(boardName: string, boardUrl: string): string {
  return `/**
 * ${boardName} í¬ë¡¤ëŸ¬
 * AI ìë™ ìƒì„± (Phase 5)
 * ìƒì„±ì¼: ${new Date().toISOString()}
 */

export async function crawl${boardName.replace(/\s+/g, '').replace(/[^a-zA-Z0-9]/g, '')}(page, config) {
  console.log(\`ğŸ“ \${config.name} í¬ë¡¤ë§ ì‹œì‘\`);
  
  const jobs = [];
  
  try {
    // 1. ëª©ë¡ í˜ì´ì§€ ì ‘ì†
    console.log(\`ğŸŒ ëª©ë¡ í˜ì´ì§€ ì ‘ì†: \${config.url}\`);
    await page.goto(config.url, { waitUntil: 'domcontentloaded', timeout: 30000 });
    await page.waitForTimeout(2000);
    
    // 2. ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
    let rows = [];
    const selectors = [
      'table tbody tr',
      '.board-list tbody tr',
      '.tbl_list tbody tr',
      'table tr',
      '.list-item'
    ];
    
    for (const selector of selectors) {
      rows = await page.locator(selector).all();
      if (rows.length > 0) {
        console.log(\`âœ… ì„ íƒì "\${selector}" ë¡œ \${rows.length}ê°œ ë°œê²¬\`);
        break;
      }
    }
    
    console.log(\`ğŸ“‹ ë°œê²¬ëœ ê³µê³  ìˆ˜: \${rows.length}ê°œ\`);
    
    if (rows.length === 0) {
      console.warn('âš ï¸ ê³µê³  ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      return jobs;
    }
    
    // 3. ê° ê²Œì‹œê¸€ ì²˜ë¦¬ (ìµœëŒ€ 10ê°œ)
    const maxCount = Math.min(rows.length, config.crawlBatchSize || 10);
    for (let i = 0; i < maxCount; i++) {
      try {
        const row = rows[i];
        
        // ì œëª© ë° ë§í¬ ì¶”ì¶œ
        const linkElement = await row.locator('a').first();
        const title = await linkElement.textContent();
        let href = await linkElement.getAttribute('href');
        
        if (!title || !href) {
          continue;
        }
        
        // ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
        if (!href.startsWith('http')) {
          const baseUrl = new URL(config.url);
          href = new URL(href, baseUrl.origin).href;
        }
        
        // ë‚ ì§œ ì¶”ì¶œ ì‹œë„
        let postedDate = new Date().toISOString().split('T')[0];
        try {
          const dateText = await row.locator('td').nth(2).textContent();
          if (dateText && /\\d{4}/.test(dateText)) {
            postedDate = dateText.trim().replace(/\\./g, '-');
          }
        } catch (e) {
          // ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
        }
        
        jobs.push({
          title: title.trim(),
          url: href,
          organization: config.name,
          location: 'ì§€ì—­ ë¯¸ìƒ',
          postedDate: postedDate,
          detailContent: '',
          attachmentUrl: null,
        });
        
        console.log(\`  âœ… \${i + 1}. \${title.trim()}\`);
      } catch (rowError) {
        console.warn(\`  âš ï¸ í–‰ \${i + 1} ì²˜ë¦¬ ì˜¤ë¥˜: \${rowError.message}\`);
      }
    }
    
    console.log(\`âœ… í¬ë¡¤ë§ ì™„ë£Œ: \${jobs.length}ê°œ ìˆ˜ì§‘\`);
    return jobs;
  } catch (error) {
    console.error('âŒ í¬ë¡¤ë§ ì˜¤ë¥˜:', error);
    return jobs;
  }
}
`
}
